{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e66b3d40-90aa-4375-acf6-b7788d315178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_10 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,609</span> (393.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,609\u001b[0m (393.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,609</span> (393.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,609\u001b[0m (393.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">101,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m12,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │       \u001b[38;5;34m101,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,064</span> (445.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m114,064\u001b[0m (445.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,064</span> (445.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m114,064\u001b[0m (445.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Generator Loss: 0.628, Discriminator Loss: 0.823, Accuracy: 0.504\n",
      "Epoch 2/100, Generator Loss: 0.758, Discriminator Loss: 0.826, Accuracy: 0.500\n",
      "Epoch 3/100, Generator Loss: 0.789, Discriminator Loss: 0.834, Accuracy: 0.488\n",
      "Epoch 4/100, Generator Loss: 0.806, Discriminator Loss: 0.829, Accuracy: 0.492\n",
      "Epoch 5/100, Generator Loss: 0.809, Discriminator Loss: 0.835, Accuracy: 0.475\n",
      "Epoch 6/100, Generator Loss: 0.819, Discriminator Loss: 0.840, Accuracy: 0.477\n",
      "Epoch 7/100, Generator Loss: 0.824, Discriminator Loss: 0.840, Accuracy: 0.478\n",
      "Epoch 8/100, Generator Loss: 0.826, Discriminator Loss: 0.843, Accuracy: 0.476\n",
      "Epoch 9/100, Generator Loss: 0.829, Discriminator Loss: 0.844, Accuracy: 0.472\n",
      "Epoch 10/100, Generator Loss: 0.833, Discriminator Loss: 0.842, Accuracy: 0.476\n",
      "Epoch 11/100, Generator Loss: 0.832, Discriminator Loss: 0.838, Accuracy: 0.477\n",
      "Epoch 12/100, Generator Loss: 0.828, Discriminator Loss: 0.837, Accuracy: 0.483\n",
      "Epoch 13/100, Generator Loss: 0.828, Discriminator Loss: 0.836, Accuracy: 0.486\n",
      "Epoch 14/100, Generator Loss: 0.828, Discriminator Loss: 0.836, Accuracy: 0.489\n",
      "Epoch 15/100, Generator Loss: 0.828, Discriminator Loss: 0.833, Accuracy: 0.491\n",
      "Epoch 16/100, Generator Loss: 0.826, Discriminator Loss: 0.835, Accuracy: 0.494\n",
      "Epoch 17/100, Generator Loss: 0.828, Discriminator Loss: 0.833, Accuracy: 0.494\n",
      "Epoch 18/100, Generator Loss: 0.827, Discriminator Loss: 0.834, Accuracy: 0.494\n",
      "Epoch 19/100, Generator Loss: 0.828, Discriminator Loss: 0.832, Accuracy: 0.495\n",
      "Epoch 20/100, Generator Loss: 0.827, Discriminator Loss: 0.831, Accuracy: 0.495\n",
      "Epoch 21/100, Generator Loss: 0.825, Discriminator Loss: 0.830, Accuracy: 0.497\n",
      "Epoch 22/100, Generator Loss: 0.826, Discriminator Loss: 0.830, Accuracy: 0.498\n",
      "Epoch 23/100, Generator Loss: 0.825, Discriminator Loss: 0.831, Accuracy: 0.498\n",
      "Epoch 24/100, Generator Loss: 0.827, Discriminator Loss: 0.830, Accuracy: 0.497\n",
      "Epoch 25/100, Generator Loss: 0.826, Discriminator Loss: 0.833, Accuracy: 0.497\n",
      "Epoch 26/100, Generator Loss: 0.828, Discriminator Loss: 0.833, Accuracy: 0.497\n",
      "Epoch 27/100, Generator Loss: 0.829, Discriminator Loss: 0.835, Accuracy: 0.497\n",
      "Epoch 28/100, Generator Loss: 0.831, Discriminator Loss: 0.836, Accuracy: 0.495\n",
      "Epoch 29/100, Generator Loss: 0.831, Discriminator Loss: 0.835, Accuracy: 0.498\n",
      "Epoch 30/100, Generator Loss: 0.831, Discriminator Loss: 0.834, Accuracy: 0.498\n",
      "Epoch 31/100, Generator Loss: 0.831, Discriminator Loss: 0.835, Accuracy: 0.498\n",
      "Epoch 32/100, Generator Loss: 0.832, Discriminator Loss: 0.836, Accuracy: 0.497\n",
      "Epoch 33/100, Generator Loss: 0.833, Discriminator Loss: 0.837, Accuracy: 0.496\n",
      "Epoch 34/100, Generator Loss: 0.834, Discriminator Loss: 0.837, Accuracy: 0.495\n",
      "Epoch 35/100, Generator Loss: 0.834, Discriminator Loss: 0.837, Accuracy: 0.494\n",
      "Epoch 36/100, Generator Loss: 0.834, Discriminator Loss: 0.837, Accuracy: 0.494\n",
      "Epoch 37/100, Generator Loss: 0.834, Discriminator Loss: 0.838, Accuracy: 0.493\n",
      "Epoch 38/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.494\n",
      "Epoch 39/100, Generator Loss: 0.834, Discriminator Loss: 0.837, Accuracy: 0.494\n",
      "Epoch 40/100, Generator Loss: 0.834, Discriminator Loss: 0.837, Accuracy: 0.494\n",
      "Epoch 41/100, Generator Loss: 0.835, Discriminator Loss: 0.838, Accuracy: 0.494\n",
      "Epoch 42/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.493\n",
      "Epoch 43/100, Generator Loss: 0.834, Discriminator Loss: 0.837, Accuracy: 0.494\n",
      "Epoch 44/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.494\n",
      "Epoch 45/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.495\n",
      "Epoch 46/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.495\n",
      "Epoch 47/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.495\n",
      "Epoch 48/100, Generator Loss: 0.835, Discriminator Loss: 0.838, Accuracy: 0.495\n",
      "Epoch 49/100, Generator Loss: 0.836, Discriminator Loss: 0.837, Accuracy: 0.495\n",
      "Epoch 50/100, Generator Loss: 0.835, Discriminator Loss: 0.838, Accuracy: 0.495\n",
      "Epoch 51/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.496\n",
      "Epoch 52/100, Generator Loss: 0.835, Discriminator Loss: 0.838, Accuracy: 0.497\n",
      "Epoch 53/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.497\n",
      "Epoch 54/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.498\n",
      "Epoch 55/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.498\n",
      "Epoch 56/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.498\n",
      "Epoch 57/100, Generator Loss: 0.836, Discriminator Loss: 0.837, Accuracy: 0.498\n",
      "Epoch 58/100, Generator Loss: 0.836, Discriminator Loss: 0.837, Accuracy: 0.498\n",
      "Epoch 59/100, Generator Loss: 0.835, Discriminator Loss: 0.836, Accuracy: 0.499\n",
      "Epoch 60/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.499\n",
      "Epoch 61/100, Generator Loss: 0.835, Discriminator Loss: 0.837, Accuracy: 0.498\n",
      "Epoch 62/100, Generator Loss: 0.835, Discriminator Loss: 0.836, Accuracy: 0.499\n",
      "Epoch 63/100, Generator Loss: 0.835, Discriminator Loss: 0.836, Accuracy: 0.500\n",
      "Epoch 64/100, Generator Loss: 0.834, Discriminator Loss: 0.836, Accuracy: 0.500\n",
      "Epoch 65/100, Generator Loss: 0.834, Discriminator Loss: 0.836, Accuracy: 0.500\n",
      "Epoch 66/100, Generator Loss: 0.834, Discriminator Loss: 0.836, Accuracy: 0.500\n",
      "Epoch 67/100, Generator Loss: 0.834, Discriminator Loss: 0.836, Accuracy: 0.500\n",
      "Epoch 68/100, Generator Loss: 0.834, Discriminator Loss: 0.835, Accuracy: 0.500\n",
      "Epoch 69/100, Generator Loss: 0.833, Discriminator Loss: 0.835, Accuracy: 0.500\n",
      "Epoch 70/100, Generator Loss: 0.834, Discriminator Loss: 0.835, Accuracy: 0.500\n",
      "Epoch 71/100, Generator Loss: 0.833, Discriminator Loss: 0.835, Accuracy: 0.500\n",
      "Epoch 72/100, Generator Loss: 0.833, Discriminator Loss: 0.835, Accuracy: 0.500\n",
      "Epoch 73/100, Generator Loss: 0.834, Discriminator Loss: 0.835, Accuracy: 0.500\n",
      "Epoch 74/100, Generator Loss: 0.834, Discriminator Loss: 0.835, Accuracy: 0.500\n",
      "Epoch 75/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.501\n",
      "Epoch 76/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.501\n",
      "Epoch 77/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.501\n",
      "Epoch 78/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 79/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.501\n",
      "Epoch 80/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.501\n",
      "Epoch 81/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.501\n",
      "Epoch 82/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.501\n",
      "Epoch 83/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.501\n",
      "Epoch 84/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 85/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 86/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 87/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 88/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 89/100, Generator Loss: 0.832, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 90/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 91/100, Generator Loss: 0.832, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 92/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 93/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 94/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 95/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 96/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.500\n",
      "Epoch 97/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.499\n",
      "Epoch 98/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.499\n",
      "Epoch 99/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.499\n",
      "Epoch 100/100, Generator Loss: 0.833, Discriminator Loss: 0.834, Accuracy: 0.499\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def load():\n",
    "    (trainX, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "    X = trainX.astype('float32') / 127.5 - 1\n",
    "    X = np.expand_dims(X, axis=-1)\n",
    "    return X\n",
    "\n",
    "def discriminator():\n",
    "    input_layer = layers.Input(shape=(28, 28, 1))\n",
    "    x = layers.Flatten()(input_layer)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(0.4)(x)  \n",
    "    output_layer = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003, beta_1=0.5),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def generator(latent_dim):\n",
    "    input_layer = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(128, activation='relu')(input_layer)\n",
    "    x = layers.Dense(784, activation='tanh')(x)\n",
    "    output_layer = layers.Reshape((28, 28, 1))(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "def real(dataset, n_samples):\n",
    "    idx = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[idx]\n",
    "    y = np.ones((n_samples, 1)) * 0.9  \n",
    "    return X, y\n",
    "\n",
    "def fake(generator, latent_dim, n_samples):\n",
    "    noise = np.random.randn(n_samples, latent_dim)\n",
    "    X = generator.predict(noise, verbose=0)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "def train_discriminator(discriminator, generator, dataset, latent_dim, epochs=100, batch_size=128):\n",
    "    batches_per_epoch = dataset.shape[0] // batch_size\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(batches_per_epoch):\n",
    "            # Train on real data\n",
    "            X_real, y_real = real(dataset, batch_size // 2)\n",
    "            X_fake, y_fake = fake(generator, latent_dim, batch_size // 2)\n",
    "            \n",
    "          \n",
    "            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
    "            \n",
    "           \n",
    "            discriminator_loss, discriminator_acc = discriminator.train_on_batch(X, y)\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Discriminator Loss: {discriminator_loss:.3f}, Accuracy: {discriminator_acc:.3f}\")\n",
    "def train_gan(generator, discriminator, dataset, latent_dim, epochs=100, batch_size=128):\n",
    "    for epoch in range(epochs):\n",
    "        noise = np.random.randn(batch_size, latent_dim)\n",
    "        X_fake = generator.predict(noise, verbose=0)\n",
    "        y_fake = np.zeros((batch_size, 1))\n",
    "\n",
    "      \n",
    "        discriminator.trainable = False  \n",
    "        generator_loss = discriminator.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "      \n",
    "        discriminator.trainable = True \n",
    "        X_real, y_real = real(dataset, batch_size // 2)\n",
    "        X_fake, y_fake = fake(generator, latent_dim, batch_size // 2)\n",
    "        \n",
    "     \n",
    "        X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
    "        \n",
    " \n",
    "        discriminator_loss, discriminator_acc = discriminator.train_on_batch(X, y)\n",
    "\n",
    "   \n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Generator Loss: {generator_loss[0]:.3f}, Discriminator Loss: {discriminator_loss:.3f}, Accuracy: {discriminator_acc:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    latent_dim = 100\n",
    "    dataset = load()\n",
    "    discriminator = discriminator()\n",
    "    generator = generator(latent_dim)\n",
    "\n",
    "    print(\"Discriminator Summary:\")\n",
    "    discriminator.summary()\n",
    "\n",
    "    print(\"Generator Summary:\")\n",
    "    generator.summary()\n",
    "\n",
    "    train_gan(generator, discriminator, dataset, latent_dim, epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151bc2e8-05cc-4766-a677-57293d6f7e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
